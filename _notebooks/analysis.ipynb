{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Definition\n",
    "I seek correlation between sleep data and exercise data.\n",
    "\n",
    "Sleep and exercise data extracted from Garmin Connect using GarminDB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Acquisition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Make the graphs a bit prettier and bigger\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Data/Data in CSV/DailySummary.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m files \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Data/Data in CSV/DailySummary.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      2\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Data/Data in CSV/DailySleepSummary.csv\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Read CSV files into dataframes\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m df_daily_summary \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(files[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      6\u001b[0m df_daily_sleep_summary \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(files[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Print columns of dataframes\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Data/Data in CSV/DailySummary.csv'"
     ]
    }
   ],
   "source": [
    "files = ['./Data/Data in CSV/DailySummary.csv', \n",
    "         './Data/Data in CSV/DailySleepSummary.csv']\n",
    "\n",
    "# Read CSV files into dataframes\n",
    "df_daily_summary = pd.read_csv(files[0])\n",
    "df_daily_sleep_summary = pd.read_csv(files[1])\n",
    "\n",
    "# Print columns of dataframes\n",
    "print(df_daily_summary.columns)\n",
    "print(df_daily_sleep_summary.columns)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "unnecessary_columns_for_daily_summary = ['weight_avg', 'weight_min', 'weight_max', 'calories_goal', 'steps_goal', 'floors_goal', \n",
    "                       'sleep_min', 'sleep_max', 'rem_sleep_min', 'rem_sleep_max', 'calories_bmr_avg', \n",
    "                       'calories_goal', 'calories_consumed_avg', 'activities', 'activities_calories', 'activities_distance', \n",
    "                       'hydration_goal', 'hydration_avg', 'hydration_intake', 'sweat_loss', 'sweat_loss_avg', 'spo2_avg', \n",
    "                       'spo2_min','rr_waking_avg', 'rr_min', 'rr_max', 'bb_max', 'bb_min', 'inactive_hr_avg', 'inactive_hr_min',\n",
    "                       'inactive_hr_max', 'hr_min', 'intensity_time_goal', 'rhr_avg', 'rhr_min', 'rhr_max', 'vigorous_activity_time']  \n",
    "\n",
    "df_daily_summary.drop(columns=unnecessary_columns_for_daily_summary, inplace=True)\n",
    "\n",
    "unnecessary_columns_for_daily_sleep_summary = ['avg_spo2', 'avg_rr']\n",
    "df_daily_sleep_summary.drop(columns=unnecessary_columns_for_daily_sleep_summary, inplace=True)\n",
    "\n",
    "# Change column names\n",
    "new_column_names = {\n",
    "    'sleep_avg': 'total_sleep',\n",
    "    'rem_sleep_avg': 'rem_sleep',\n",
    "    'stress_avg': 'stress',\n",
    "    'calories_avg': 'calories',\n",
    "    'calories_active_avg': 'calories_active',\n",
    "    'awake' : 'awake_duration',\n",
    "    'start' : 'start_time',\n",
    "    'end' : 'end_time',\n",
    "    'intensity_time' : 'intensity_duration',\n",
    "    'moderate_activity_time' : 'moderate_activity_duration',\n",
    "}\n",
    "\n",
    "df_daily_summary.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "new_column_names_2 = {\n",
    "    'avg_stress': 'stress',\n",
    "    'awake' : 'awake_duration',\n",
    "    'start' : 'start_time',\n",
    "    'end' : 'end_time'\n",
    "}\n",
    "\n",
    "df_daily_sleep_summary.rename(columns=new_column_names_2, inplace=True)\n",
    "\n",
    "print(\"\\nAfter changes, the columns of the dataframes are: \")\n",
    "print(df_daily_summary.columns)\n",
    "print(df_daily_sleep_summary.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure 'day' is the index in both dataframes\n",
    "df_daily_summary.set_index('day', inplace=True)\n",
    "df_daily_sleep_summary.set_index('day', inplace=True)\n",
    "\n",
    "# Combine dataframes and fill null values\n",
    "merged_df = df_daily_summary.combine_first(df_daily_sleep_summary)\n",
    "\n",
    "# Reset index\n",
    "merged_df.reset_index(inplace=True)\n",
    "\n",
    "# Sort by day\n",
    "merged_df.sort_values(by='day', inplace=True)\n",
    "\n",
    "# Drop the first row\n",
    "merged_df = merged_df.drop(merged_df.index[0])\n",
    "\n",
    "# Drop the rows without qualifier value\n",
    "merged_df = merged_df.dropna(subset=['qualifier'])\n",
    "\n",
    "print(\"After changes, the columns:\")\n",
    "print(merged_df.columns)\n",
    "print(merged_df.head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection and Handling\n",
    "- Handle negative stress values\n",
    "- Impute with mean values of corresponding column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTLIER DETECTION AND HANDLING\n",
    "\n",
    "# Outlier calculating using IQR method\n",
    "def calculate_outliers(df):\n",
    "    # Select only numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=[np.number])\n",
    "\n",
    "    # Calculate Q1, Q3, and IQR on numeric columns\n",
    "    Q1 = numeric_cols.quantile(0.25)\n",
    "    Q3 = numeric_cols.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Identify outliers\n",
    "    # Create a list to store the outlier information\n",
    "    outlier_info = []\n",
    "\n",
    "    # Iterate over each column\n",
    "    for col in numeric_cols.columns:\n",
    "        # Identify outliers in this column\n",
    "        col_outliers = (numeric_cols[col] < (Q1[col] - 1.5 * IQR[col])) | (numeric_cols[col] > (Q3[col] + 1.5 * IQR[col]))\n",
    "        # Add outlier information to the list\n",
    "        for row in col_outliers[col_outliers].index:\n",
    "            outlier_info.append({'row': row, 'column': col, 'value': numeric_cols.loc[row, col]})\n",
    "\n",
    "    # Convert the list to a DataFrame\n",
    "    outlier_info = pd.DataFrame(outlier_info)\n",
    "\n",
    "    return outlier_info\n",
    "\n",
    "outlier_info = calculate_outliers(merged_df)\n",
    "#print(outlier_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative STRESS values are due to error -> replace with mean\n",
    "\n",
    "# Create a boolean mask for rows with outliers\n",
    "outlier_rows = merged_df.index.isin(outlier_info['row'])\n",
    "\n",
    "# Calculate the mean of the non-outlier 'STRESS' values\n",
    "mean_stress = merged_df.loc[~outlier_rows, 'stress'].mean()\n",
    "\n",
    "# Replace the negative 'STRESS' values in the outliers with the mean\n",
    "merged_df.loc[outlier_rows & (merged_df['stress'] < 0), 'stress'] = mean_stress\n",
    "\n",
    "# Replace outliers with the median of the column\n",
    "for index, row in outlier_info.iterrows():\n",
    "    merged_df.loc[row['row'], row['column']] = merged_df[row['column']].median()\n",
    "\n",
    "# Update the outliers \n",
    "outlier_info = calculate_outliers(merged_df)\n",
    "\n",
    "# Now print the DataFrame\n",
    "print(outlier_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle time duration values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_cols = ['awake_duration', 'rem_sleep', 'total_sleep', 'deep_sleep', 'light_sleep', 'intensity_duration', 'moderate_activity_duration']\n",
    "\n",
    "# Convert each column to timedelta\n",
    "for column in duration_cols:\n",
    "    merged_df[column] = pd.to_timedelta(merged_df[column], errors='coerce')\n",
    "\n",
    "print(\"\\nAfter converting to timedelta:\")\n",
    "print(merged_df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling date values by converting into datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['day'] = pd.to_datetime(merged_df['day'])\n",
    "merged_df['start_time'] = pd.to_datetime(merged_df['start_time'])\n",
    "merged_df['end_time'] = pd.to_datetime(merged_df['end_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle missing numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of missing values in each column\n",
    "print(merged_df.isnull().sum())\n",
    "\n",
    "# Handle numeric missing values by filling with the mean of respective columns\n",
    "numeric_columns = merged_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "merged_df[numeric_columns] = merged_df[numeric_columns].fillna(merged_df[numeric_columns].mean())\n",
    "\n",
    "print(\"\\nAfter handling missing values:\")\n",
    "\n",
    "if merged_df.isnull().sum().sum() == 0:\n",
    "    print(\"No missing values in the DataFrame after handling missing values\")\n",
    "else :\n",
    "    print(\"Missing values still exist in the DataFrame after handling missing values\")\n",
    "    print(merged_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Derive new features\n",
    "- active ratio\n",
    "- stress_level: Refer to [this website](https://www.garmin.com.my/minisite/garmin-technology/health-science/stress-tracking/#:~:text=A%20score%20from%20zero%20to,to%20keep%20stress%20in%20check) for categorization choice\n",
    "- steps_level\n",
    "- day_of_week\n",
    "- 7-day moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering: New features\n",
    "# Active Ratio\n",
    "merged_df['active_ratio'] = merged_df['calories_active'] / merged_df['calories']\n",
    "\n",
    "# Stress Level Categories\n",
    "merged_df['stress_level'] = pd.cut(merged_df['stress'], bins=[0, 25, 50, 75, 100], labels=['Rest', 'Low', 'Medium', 'High'])\n",
    "\n",
    "# Steps Level\n",
    "merged_df['steps_level'] = pd.cut(merged_df['steps'], bins=[0, 2500, 5000, 7500, 10000, np.inf], labels=['Sedentary', 'Lightly Active', 'Active', 'Very Active', 'Super Active'])\n",
    "\n",
    "# Day of the Week\n",
    "# 'day' is in the format 'YYYY-MM-DD'\n",
    "merged_df['day_of_week'] = pd.to_datetime(merged_df['day']).dt.day_name()\n",
    "\n",
    "# Calculate the 7-day moving average\n",
    "merged_df['7_day_avg'] = merged_df['score'].rolling(window=7).mean()\n",
    "# Order the days of the week\n",
    "ordered_days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "average_7_day_avg = merged_df.groupby('day_of_week')['7_day_avg'].mean().reindex(ordered_days)\n",
    "\n",
    "#print(merged_df.head(1))\n",
    "\n",
    "print(merged_df['stress_level'].value_counts())\n",
    "print(merged_df['steps_level'].value_counts())\n",
    "print(merged_df['day_of_week'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns for activeness\n",
    "activeness_features = ['calories', 'calories_active', 'steps', 'floors', 'intensity_duration_mins', 'moderate_activity_duration_mins']\n",
    "\n",
    "# List of columns for the second correlation\n",
    "sleep_features = ['light_sleep_mins', 'deep_sleep_mins', 'rem_sleep_mins', 'total_sleep_mins', 'score', 'qualifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Properties of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSummary statistics of numeric values:\")\n",
    "print(merged_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of timedelta columns\n",
    "print(merged_df[duration_cols].dtypes)\n",
    "\n",
    "for col in duration_cols:\n",
    "    merged_df[col + '_mins'] = merged_df[col].dt.total_seconds() / 60\n",
    "\n",
    "print(\"\\nAfter adding _mins columns:\")\n",
    "print(merged_df.head(1))\n",
    "\n",
    "# Initialize a scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Create a new DataFrame for the normalized columns\n",
    "normalized_df = merged_df.copy()\n",
    "\n",
    "# List of numerical columns\n",
    "num_cols = ['calories', 'calories_active', 'floors', 'hr_avg', 'hr_max', 'score', 'steps', 'stress']\n",
    "\n",
    "# List of columns to normalize\n",
    "cols_to_normalize = num_cols + [t + '_mins' for t in duration_cols]\n",
    "\n",
    "# Normalize the columns\n",
    "normalized_df[cols_to_normalize] = scaler.fit_transform(normalized_df[cols_to_normalize])\n",
    "\n",
    "print(\"\\nAfter normalization:\")\n",
    "print(normalized_df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of pairs of columns to be plotted together\n",
    "column_pairs = [\n",
    "    ['awake_duration_mins', 'rem_sleep_mins', 'total_sleep_mins', 'deep_sleep_mins', 'light_sleep_mins'],\n",
    "    ['moderate_activity_duration_mins', 'intensity_duration_mins']\n",
    "]\n",
    "\n",
    "# Define titles for each plot\n",
    "titles = [\n",
    "    'Sleep Phases Density',\n",
    "    'Activity Duration Density'\n",
    "]\n",
    "\n",
    "# Define colors for each column\n",
    "colors = ['blue', 'red', 'green', 'purple', 'orange', 'yellow']\n",
    "\n",
    "# Plot active calorie expenditure distribution\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "# Box plot\n",
    "sns.boxplot(x=normalized_df['calories_active'], color='blue', ax=axs[0])\n",
    "# Histogram\n",
    "sns.histplot(normalized_df['calories_active'], kde=True, color='red', ax=axs[1])\n",
    "# Common title\n",
    "plt.suptitle('Active Calorie Expenditure Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot steps distribution\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "# Box plot\n",
    "sns.boxplot(x=normalized_df['steps'], color='blue', ax=axs[0])\n",
    "# Histogram\n",
    "sns.histplot(normalized_df['steps'], kde=True, color='red', ax=axs[1])\n",
    "# Common title\n",
    "plt.suptitle('Step Count Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for pair, title in zip(column_pairs, titles):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for col, color in zip(pair, colors):\n",
    "        data = normalized_df[col]\n",
    "        if pair == ['awake_duration_mins', 'rem_sleep_mins', 'total_sleep_mins', 'deep_sleep_mins', 'light_sleep_mins']:\n",
    "            sns.kdeplot(data, color=color, label=col.capitalize())\n",
    "        else:\n",
    "            sns.histplot(data, kde=True, color=color, label=col.capitalize())\n",
    "    plt.title(title)\n",
    "    plt.legend(title='Columns')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of sleep start and end times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting datetime columns as histograms\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Define colors for each column\n",
    "colors = ['blue', 'red']\n",
    "\n",
    "# Plotting datetime columns as histograms\n",
    "datetime_cols = ['start_time', 'end_time']\n",
    "for col, color in zip(datetime_cols, colors):\n",
    "    sns.histplot(normalized_df[col].dt.hour, kde=True, bins=24, color=color, label=col.capitalize())  # Plot histogram of the hour of the day\n",
    "\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.title('Histogram of Start and End Hours')\n",
    "plt.legend(title='Sleep Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of sleep quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['day'] = pd.to_datetime(merged_df['day'])\n",
    "merged_df.set_index('day', inplace=True)\n",
    "\n",
    "merged_df['score'].plot(figsize=(10, 6))\n",
    "plt.title('Sleep Score Over Time')\n",
    "plt.show()\n",
    "\n",
    "# Calculate the 7-day moving average\n",
    "merged_df['7_day_avg'] = merged_df['score'].rolling(window=7).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting categorical columns\n",
    "sns.countplot(x='qualifier', data=normalized_df)\n",
    "plt.title('Sleep Quality Distribution') \n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring which days of the week I sleep better & weekly sleep fluctuation\n",
    "**Finding**:\n",
    "- It turns out I have a pretty average weekly sleep score of an approximate 80\n",
    "- From Monday to Tuesday a steep decrease is observed\n",
    "- From Friday to weekend a steep increase is observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average sleep score for each day of the week\n",
    "average_scores = merged_df.groupby('day_of_week')['score'].mean()\n",
    "\n",
    "average_scores = average_scores.reindex(ordered_days)\n",
    "\n",
    "# Create a bar plot of the average sleep scores\n",
    "ax = average_scores.plot(kind='bar', figsize=(10, 6), alpha=0.5, color='b')\n",
    "\n",
    "# Create a line plot of the 7-day moving average\n",
    "ax2 = average_7_day_avg.plot(kind='line', marker='o', secondary_y=True, ax=ax)\n",
    "\n",
    "ax.set_xlabel('') # Hide x-axis label\n",
    "ax2.set_yticklabels([]) # Hide y-axis labels on secondary y-axis\n",
    "ax2.set_yticks([]) # Hide y-axis ticks on secondary y-axis\n",
    "plt.title('Average Sleep Score and 7-Day Moving Average by Day of the Week')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring correlation between stress level and sleep score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'stress' and 'score' are columns in your DataFrame\n",
    "sns.regplot(x='stress', y='score', data=normalized_df)\n",
    "plt.show()\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = normalized_df[['stress', 'score']].corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring correlation between stress level and physical activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode stress_level feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode 'stress' and 'stress_level'\n",
    "normalized_df['stress_encoded'] = le.fit_transform(normalized_df['stress'])\n",
    "normalized_df['stress_level_encoded'] = le.fit_transform(normalized_df['stress_level'])\n",
    "\n",
    "# Add 'stress_encoded' and 'stress_level_encoded' to the list of features\n",
    "features = ['stress_encoded', 'stress_level_encoded'] + activeness_features\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = normalized_df[features].corr()\n",
    "\n",
    "# Print the correlation of 'stress_encoded' and 'stress_level_encoded' with each feature\n",
    "print(correlation_matrix[['stress_encoded', 'stress_level_encoded']])\n",
    "\n",
    "# Plot the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap of Encoded Stress Level and Activeness Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode 'stress_level'\n",
    "normalized_df['stress_level_encoded'] = le.fit_transform(normalized_df['stress_level'])\n",
    "\n",
    "# Add 'stress_level_encoded' to the list of features\n",
    "features = ['stress_level_encoded'] + activeness_features\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = normalized_df[features].corr()\n",
    "\n",
    "# Print the correlation of 'stress_level_encoded' with each feature\n",
    "print(correlation_matrix['stress_level_encoded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring correlation between sleep features and sleep quality\n",
    "\n",
    "**Aim**:\n",
    "- To understand how sleep data are consistent with each other\n",
    "- Correlation between deep sleep, REM sleep, total sleep, score, and start time. \n",
    "\n",
    "**Techniques used:**\n",
    "- Label encoding is applied to handle string values before seeking correlation\n",
    "\n",
    "**Finding**:\n",
    "- Sleep score and sleep durations influence sleep quality positively \n",
    "- However, deep sleep duration has low correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit the label encoder with the 'qualifier' column\n",
    "le.fit(normalized_df['qualifier'])\n",
    "\n",
    "# Define the mapping\n",
    "# reverse the mapping\n",
    "qualifier_mapping = {'INVALID': 0, 'POOR': 1, 'FAIR': 2, 'GOOD': 3, 'EXCELLENT': 4}\n",
    "# reverse\n",
    "\n",
    "# Apply the mapping to the 'qualifier' column\n",
    "normalized_df['qualifier'] = normalized_df['qualifier'].map(qualifier_mapping)\n",
    "\n",
    "# Print the unique values in the 'qualifier' column to verify\n",
    "print(normalized_df['qualifier'].unique())\n",
    "\n",
    "# Print the unique values and their encoding\n",
    "for value, encoding in qualifier_mapping.items():\n",
    "    print(f'{value}: {encoding}')\n",
    "    \n",
    "# Print the unique values in the 'qualifier' column of normalized_df that are not in the qualifier_mapping dictionary\n",
    "print(set(normalized_df['qualifier'].unique()) - set(qualifier_mapping.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr2 = normalized_df[sleep_features].corr()\n",
    "\n",
    "# Plot the correlation matrix for the second set of columns\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr2, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation between Sleep Features and Sleep Quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring correlation between activeness and sleep quality\n",
    "**Aim:**\n",
    "- To understand the correlation between activeness and the quality of sleep.\n",
    "- Specifically, correlation between calories, active calories, average heart rate, maximum heart rate, steps, steps level, floors, intensity time, moderate activity time, and the qualifier. This will help us understand how daily activity levels (activeness) correlate with sleep quality.\n",
    "\n",
    "**Techniques used:**\n",
    "- Label encoding is applied to handle string values before seeking correlation\n",
    "- Kendall's Tau for correlation calculation \n",
    "- It is proved that complex ML models such as DecisionTree, RandomForest have low accuracy due to small data size\n",
    "\n",
    "**Finding:**\n",
    "- Surprisingly, activeness has slight negative impact on sleep quality and duration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation for each feature using **Pearson's Correlation Coefficient** method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine two lists\n",
    "corr_list = activeness_features + sleep_features\n",
    "\n",
    "# Calculate the correlation matrix for the first set of columns\n",
    "corr1 = normalized_df[corr_list].corr()\n",
    "\n",
    "# Plot the correlation matrix for the first set of columns\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr1, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation between Activeness Metrics and Sleep Quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between activeness and sleep score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_with_qualifier = normalized_df[['steps', 'calories_active', 'intensity_duration_mins', 'moderate_activity_duration_mins', 'score']].corr()\n",
    "\n",
    "#print(\"Correlation with qualifier:\")\n",
    "#print(corr_with_qualifier)\n",
    "\n",
    "# Plot the correlation matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_with_qualifier, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation with Qualifier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further analysis of the relationship between activeness and sleep quality using a **decision tree model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature columns and the target column\n",
    "feature_cols = ['steps', 'calories_active', 'intensity_duration_mins', 'moderate_activity_duration_mins', 'deep_sleep_mins']\n",
    "target_col = 'qualifier'\n",
    "\n",
    "# Split the data into training and test sets with stratified sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(merged_df[feature_cols], merged_df[target_col], test_size=0.2, random_state=42, stratify=merged_df[target_col])\n",
    "\n",
    "# Create and fit the decision tree model\n",
    "model = DecisionTreeClassifier(max_depth=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set and calculate the accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {'max_depth': range(1, 10)}\n",
    "\n",
    "# Create the grid search object\n",
    "grid = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search object to the data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(f'Best parameters: {grid.best_params_}')\n",
    "print(f'Best score: {grid.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between activeness and sleep start time\n",
    "\n",
    "Using **Pearson's Correlation Coefficient**. Why choose this method?\n",
    "- SRC does not assume datasets are normally distributed\n",
    "- Can be used when the relationship is not linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_with_start_time = normalized_df[activeness_features + ['start_time']].corr()\n",
    "\n",
    "# Plot the correlation matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_with_start_time, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation with start_time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing and Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sleep duration ~ Sleep quality\n",
    "**Null hypothesis:** There is no correlation between sleep duration and sleep quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation, p_value = pearsonr(normalized_df['total_sleep_mins'], normalized_df['score'])\n",
    "\n",
    "print(f'Correlation: {correlation}')\n",
    "print(f'P-value: {p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing\n",
    "Using Pearson correlation test, \n",
    "- Correlation: 0.6300386664844899\n",
    "- p-value: 7.461805108064072e-24\n",
    "### Conclusion\n",
    "p-value is extremelly small. Hence, assuming there is no actual corrolation, the probability of observing such strong correlation by chance is extremely low.\n",
    "\n",
    "Null hypothesis can be rejected. This correlation is statistically significant provides strong evidence for an alternative hypothesis that **as sleep duration increases, sleep quality also increases**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active calorie burned ~ Sleep score\n",
    "**Null hypothesis:** There's no correlation between active calorie burned and sleep score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "correlation, p_value = pearsonr(normalized_df['calories_active'], normalized_df['score'])\n",
    "\n",
    "print(f'Correlation: {correlation}')\n",
    "print(f'P-value: {p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing\n",
    "Using Pearson correlation test, \n",
    "- Correlation: -0.24184153456526303\n",
    "- p-value: 0.0005086136505719167\n",
    "\n",
    "### Conclusion\n",
    "The p-value is extremely small (=< 0.05). Assuming no correlation, this strong correlation cannot occur by chance.\n",
    "\n",
    "Null hypothesis can be rejected.  Hence this correlation is statistically significant and provides evidence for an alternative hypothesis that **as active calories burned increase, sleep score decreases**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step count ~ Sleep start time\n",
    "**Null hypothesis:** No correlation between step count and sleep start time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'start_time' to the number of seconds past 11PM\n",
    "reference_time = pd.Timestamp('23:00:00')\n",
    "normalized_df['start_time_seconds'] = ((normalized_df['start_time'] - reference_time).dt.total_seconds()) % (24*3600)\n",
    "\n",
    "correlation, p_value = pearsonr(normalized_df['steps'], normalized_df['start_time_seconds'])\n",
    "\n",
    "print(f'Correlation: {correlation}')\n",
    "print(f'P-value: {p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing\n",
    "Using Pearson correlation test, \n",
    "- Correlation: -0.11377001817658312\n",
    "- p-value: 0.1060477403348315\n",
    "\n",
    "### Conclusion\n",
    "The p-value is higher than 0.05, meaning that assuming there's no correlation, this statistics is not statistically significant as it may be occurred by random chance. No strong evidence against null hypothesis, therefore null hypothesis cannot be rejected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stress level ~ Sleep quality\n",
    "**Null Hypothesis**: No correlation between stress level and sleep quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalized_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m chi2_contingency\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Create a contingency table\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m contingency_table \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mcrosstab(normalized_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstress_level\u001b[39m\u001b[38;5;124m'\u001b[39m], normalized_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqualifier\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Perform the Chi-square test\u001b[39;00m\n\u001b[1;32m      7\u001b[0m chi2, p_value, dof, expected \u001b[38;5;241m=\u001b[39m chi2_contingency(contingency_table)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'normalized_df' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(normalized_df['stress_level'], normalized_df['qualifier'])\n",
    "\n",
    "# Perform the Chi-square test\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(f'Chi-square statistic: {chi2}')\n",
    "print(f'P-value: {p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing\n",
    "Using chi-square test\n",
    "- Chi-square statistic: 12.612769040617142\n",
    "- p-value: 0.013331362158689679\n",
    "\n",
    "### Conclusion\n",
    "The p-value is small (=< 0.05), meaning that there is statistically significant association between stress level and sleep quality. They are not independent. Therefore we can reject the null hypothesis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
